"""
INTERFACE WEB PARA ANALISADOR DE IMAGENS E MENSAGENS
Aplica√ß√£o Flask - Compat√≠vel com desenvolvimento local e Vercel
"""

import os
import json
import shutil
import zipfile
import sys
import importlib.util
from datetime import datetime, timedelta
from pathlib import Path
from werkzeug.utils import secure_filename
from flask import Flask, render_template, request, jsonify, send_file, flash, redirect, url_for, make_response
import pandas as pd
import threading
import time
from functools import lru_cache
import gzip
from werkzeug.middleware.proxy_fix import ProxyFix

# Detectar ambiente e ajustar caminhos
def get_base_path():
    """Obt√©m o caminho base da aplica√ß√£o considerando ambiente Vercel."""
    if 'VERCEL' in os.environ:
        # Em produ√ß√£o na Vercel
        return '/tmp'
    else:
        # Em desenvolvimento local
        return os.path.dirname(os.path.abspath(__file__))

BASE_PATH = get_base_path()

# Importar otimiza√ß√µes
try:
    from src.optimizations import init_optimizations
except ImportError:
    # Fun√ß√£o vazia se n√£o conseguir importar
    def init_optimizations(app):
        pass

app = Flask(__name__, 
           template_folder=os.path.join(BASE_PATH, 'templates'),
           static_folder=os.path.join(BASE_PATH, 'static'))

app.secret_key = os.environ.get('SECRET_KEY', 'sua_chave_secreta_aqui_mude_em_producao')
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max por upload

# Otimiza√ß√µes de performance
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = timedelta(hours=1)  # Cache est√°tico
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)

# Aplicar otimiza√ß√µes
init_optimizations(app)

# Cache para configura√ß√µes
_config_cache = None
_config_cache_time = None
CONFIG_CACHE_TTL = 300  # 5 minutos

# Configura√ß√µes b√°sicas adaptadas para ambiente
UPLOAD_FOLDER = os.path.join(BASE_PATH, 'imagens_para_analisar')
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'txt'}
EXTENSOES_IMAGEM = ('.png', '.jpg', '.jpeg')
DIRETORIO_IMAGENS = UPLOAD_FOLDER
ARQUIVO_SAIDA_EXCEL = os.path.join(BASE_PATH, 'resultados', 'Relatorio_Mestre_Produtos.xlsx')
LOG_CONSUMO_FILE = os.path.join(BASE_PATH, 'resultados', 'log_consumo_tokens.txt')
LOG_PROCESSADOS_FILE = os.path.join(BASE_PATH, 'resultados', 'log_mestre.txt')
CONFIG_FILE = os.path.join(BASE_PATH, 'config', 'config.json')

# Garantir que os diret√≥rios existam
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(os.path.join(BASE_PATH, 'resultados'), exist_ok=True)

# Vari√°veis globais para controle de processamento
processamento_ativo = False
progresso_atual = {"progresso": 0, "status": "Aguardando", "logs": []}

@lru_cache(maxsize=1)
def carregar_configuracao():
    """Carrega configura√ß√µes do arquivo JSON com cache."""
    global _config_cache, _config_cache_time
    
    # Verificar cache
    current_time = time.time()
    if (_config_cache is not None and 
        _config_cache_time is not None and 
        current_time - _config_cache_time < CONFIG_CACHE_TTL):
        return _config_cache
    
    config_padrao = {
        "api": {
            "provider": "gemini",
            "gemini_api_key": os.environ.get('GEMINI_API_KEY', ''),
            "openai_api_key": os.environ.get('OPENAI_API_KEY', ''),
            "anthropic_api_key": os.environ.get('ANTHROPIC_API_KEY', '')
        },
        "processamento": {
            "modelo_gemini": "gemini-1.5-flash",
            "temperatura": 0.1,
            "max_tokens": 1000,
            "timeout": 30
        },
        "interface": {
            "tema": "claro",
            "auto_refresh": True,
            "logs_tempo_real": True
        }
    }
    
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # Mesclar com configura√ß√£o padr√£o para garantir todas as chaves
                for key in config_padrao:
                    if key not in config:
                        config[key] = config_padrao[key]
                    elif isinstance(config_padrao[key], dict):
                        for subkey in config_padrao[key]:
                            if subkey not in config[key]:
                                config[key][subkey] = config_padrao[key][subkey]
                
                # Priorizar vari√°veis de ambiente
                if os.environ.get('GEMINI_API_KEY'):
                    config['api']['gemini_api_key'] = os.environ.get('GEMINI_API_KEY')
                if os.environ.get('OPENAI_API_KEY'):
                    config['api']['openai_api_key'] = os.environ.get('OPENAI_API_KEY')
                if os.environ.get('ANTHROPIC_API_KEY'):
                    config['api']['anthropic_api_key'] = os.environ.get('ANTHROPIC_API_KEY')
                
                # Atualizar cache
                _config_cache = config
                _config_cache_time = current_time
                return config
        else:
            # Criar arquivo de configura√ß√£o padr√£o se n√£o estiver na Vercel
            if 'VERCEL' not in os.environ:
                salvar_configuracao(config_padrao)
            _config_cache = config_padrao
            _config_cache_time = current_time
            return config_padrao
    except Exception as e:
        print(f"Erro ao carregar configura√ß√£o: {e}")
        return config_padrao

def salvar_configuracao(config):
    """Salva configura√ß√µes no arquivo JSON e limpa cache."""
    global _config_cache, _config_cache_time
    
    # No ambiente Vercel, n√£o tenta salvar no filesystem (read-only)
    if 'VERCEL' in os.environ:
        print("‚ö†Ô∏è Ambiente Vercel: configura√ß√µes devem ser definidas como vari√°veis de ambiente")
        return True
        
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        # Limpar cache
        _config_cache = None
        _config_cache_time = None
        carregar_configuracao.cache_clear()
        
        return True
    except Exception as e:
        print(f"Erro ao salvar configura√ß√£o: {e}")
        return False

def carregar_logs():
    """Carrega os logs de arquivos j√° processados."""
    if not os.path.exists(LOG_PROCESSADOS_FILE):
        return set()
    try:
        with open(LOG_PROCESSADOS_FILE, 'r', encoding='utf-8') as f:
            return set(line.strip() for line in f if line.strip())
    except IOError as e:
        print(f"‚ö†Ô∏è Erro ao ler log de arquivos processados: {e}")
        return set()

def executar_processamento_principal():
    """Executa o processamento principal importando e rodando o script original."""
    global progresso_atual
    
    try:
        # Verificar se h√° configura√ß√µes v√°lidas
        config = carregar_configuracao()
        api_key = config.get("api", {}).get("gemini_api_key", "")
        
        if not api_key:
            progresso_atual["logs"].append("‚ùå Chave da API Gemini n√£o configurada!")
            progresso_atual["status"] = "Erro: API Key n√£o configurada"
            return False
        
        progresso_atual["logs"].append("üîë API Key encontrada, continuando...")
        
        # Verificar se h√° imagens para processar
        if not os.path.exists(DIRETORIO_IMAGENS):
            progresso_atual["logs"].append("‚ùå Diret√≥rio de imagens n√£o encontrado!")
            return False
        
        imagens = [f for f in os.listdir(DIRETORIO_IMAGENS) 
                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not imagens:
            progresso_atual["logs"].append("‚ùå Nenhuma imagem encontrada para processar!")
            return False
        
        progresso_atual["logs"].append(f"üì∏ Encontradas {len(imagens)} imagens para processar")
        
        # No ambiente Vercel, o processamento completo pode ser limitado
        if 'VERCEL' in os.environ:
            progresso_atual["logs"].append("‚ö†Ô∏è Ambiente Vercel: processamento completo pode ser limitado")
            return False
        
        # Importar e executar o m√≥dulo principal (apenas em desenvolvimento local)
        extrair_dados_path = os.path.join(BASE_PATH, 'src', 'extrair-dados.py')
        if os.path.exists(extrair_dados_path):
            progresso_atual["logs"].append("‚öôÔ∏è Carregando m√≥dulo de processamento...")
            spec = importlib.util.spec_from_file_location("extrair_dados", extrair_dados_path)
            extrair_dados = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(extrair_dados)
        else:
            progresso_atual["logs"].append("‚ùå Script de processamento n√£o encontrado")
            return False
        
        progresso_atual["logs"].append("üöÄ Iniciando an√°lise com IA...")
        
        # Executar a fun√ß√£o principal
        extrair_dados.main()
        
        # Verificar se o relat√≥rio foi gerado
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            progresso_atual["logs"].append("‚úÖ Relat√≥rio Excel gerado com sucesso!")
            return True
        else:
            progresso_atual["logs"].append("‚ö†Ô∏è Processamento conclu√≠do, mas relat√≥rio n√£o foi encontrado")
            return False
        
    except Exception as e:
        erro_msg = f"Erro ao executar processamento: {str(e)}"
        print(erro_msg)
        progresso_atual["logs"].append(f"‚ùå {erro_msg}")
        return False

def allowed_file(filename):
    """Verifica se o arquivo tem extens√£o permitida."""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@lru_cache(maxsize=128, typed=True)
def obter_estatisticas():
    """Obt√©m estat√≠sticas do sistema com cache."""
    stats = {
        'imagens_total': 0,
        'imagens_processadas': 0,
        'imagens_pendentes': 0,
        'ultimo_processamento': 'Nunca',
        'tokens_consumidos_hoje': 0,
        'relatorio_existe': False
    }
    
    try:
        # Contar imagens apenas se diret√≥rio mudou
        if os.path.exists(DIRETORIO_IMAGENS):
            todos_arquivos = os.listdir(DIRETORIO_IMAGENS)
            # Filtro otimizado para extens√µes de imagem
            stats['imagens_total'] = sum(1 for f in todos_arquivos 
                                       if f.lower().endswith(EXTENSOES_IMAGEM))
        
        # Imagens j√° processadas
        processadas = carregar_logs()
        stats['imagens_processadas'] = len(processadas)
        stats['imagens_pendentes'] = max(0, stats['imagens_total'] - stats['imagens_processadas'])
        
        # √öltimo processamento - cache por arquivo
        if os.path.exists(LOG_PROCESSADOS_FILE):
            mod_time = os.path.getmtime(LOG_PROCESSADOS_FILE)
            stats['ultimo_processamento'] = datetime.fromtimestamp(mod_time).strftime('%d/%m/%Y %H:%M')
        
        # Tokens consumidos hoje - otimizado
        if os.path.exists(LOG_CONSUMO_FILE):
            hoje = datetime.now().strftime('%Y-%m-%d')
            try:
                with open(LOG_CONSUMO_FILE, 'r', encoding='utf-8') as f:
                    # Ler apenas √∫ltimas linhas para performance
                    lines = f.readlines()[-50:]  # √öltimas 50 linhas
                    for linha in lines:
                        if hoje in linha and 'tokens consumidos:' in linha:
                            tokens_str = linha.split('tokens consumidos:')[1].strip().replace(',', '')
                            stats['tokens_consumidos_hoje'] += int(tokens_str)
            except (ValueError, IndexError):
                pass
        
        # Verifica se existe relat√≥rio
        stats['relatorio_existe'] = os.path.exists(ARQUIVO_SAIDA_EXCEL)
        
    except Exception as e:
        print(f"Erro ao obter estat√≠sticas: {e}")
    
    return stats

def obter_resultados_recentes():
    """Obt√©m os resultados mais recentes do relat√≥rio."""
    resultados = {'avarias': [], 'uso_interno': [], 'erros': []}
    
    try:
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            # Ler as √∫ltimas 10 entradas de cada tipo
            sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
            
            if 'Avarias' in sheets:
                df_avarias = sheets['Avarias'].tail(10)
                # Tratar valores NaN
                df_avarias = df_avarias.fillna('-')
                resultados['avarias'] = df_avarias.to_dict('records')
            
            if 'Uso Interno' in sheets:
                df_uso = sheets['Uso Interno'].tail(10)
                # Tratar valores NaN
                df_uso = df_uso.fillna('-')
                resultados['uso_interno'] = df_uso.to_dict('records')
            
            if 'Erros de An√°lise' in sheets:
                df_erros = sheets['Erros de An√°lise'].tail(10)
                # Tratar valores NaN
                df_erros = df_erros.fillna('-')
                resultados['erros'] = df_erros.to_dict('records')
                
    except Exception as e:
        print(f"Erro ao ler resultados: {e}")
    
    return resultados

def processar_em_background():
    """Executa o processamento em background."""
    global processamento_ativo, progresso_atual
    
    try:
        processamento_ativo = True
        progresso_atual = {"progresso": 0, "status": "Iniciando processamento...", "logs": []}
        
        # Log inicial
        timestamp = datetime.now().strftime('%H:%M:%S')
        progresso_atual["logs"].append(f"üöÄ Iniciando processamento √†s {timestamp}")
        
        # Verificar se estamos na Vercel
        if 'VERCEL' in os.environ:
            progresso_atual["status"] = "‚ùå Erro: Processamento n√£o dispon√≠vel na Vercel"
            progresso_atual["logs"].append("‚ùå O processamento completo n√£o est√° dispon√≠vel no ambiente Vercel")
            progresso_atual["logs"].append("üí° Use o ambiente local para processamento de imagens")
            return
        
        # Verificar configura√ß√µes
        progresso_atual["progresso"] = 5
        progresso_atual["status"] = "üîç Verificando configura√ß√µes..."
        config = carregar_configuracao()
        api_key = config.get("api", {}).get("gemini_api_key", "")
        
        if not api_key:
            progresso_atual["status"] = "‚ùå Erro: API Key n√£o configurada"
            progresso_atual["logs"].append("‚ùå Chave da API Gemini n√£o encontrada!")
            progresso_atual["logs"].append("‚öôÔ∏è Configure a API Key na p√°gina de Configura√ß√µes")
            return
        
        # Verificar imagens dispon√≠veis
        progresso_atual["progresso"] = 10
        progresso_atual["status"] = "üì∏ Verificando imagens dispon√≠veis..."
        
        if not os.path.exists(DIRETORIO_IMAGENS):
            progresso_atual["logs"].append("‚ùå Diret√≥rio de imagens n√£o encontrado")
            progresso_atual["status"] = "‚ùå Erro: Diret√≥rio n√£o encontrado"
            return
        
        imagens = [f for f in os.listdir(DIRETORIO_IMAGENS) 
                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        if not imagens:
            progresso_atual["logs"].append("‚ùå Nenhuma imagem encontrada para processar")
            progresso_atual["status"] = "‚ùå Erro: Nenhuma imagem encontrada"
            return
        
        progresso_atual["logs"].append(f"üì∏ Encontradas {len(imagens)} imagens para processar")
        
        # Verificar imagens j√° processadas
        progresso_atual["progresso"] = 20
        progresso_atual["status"] = "üìã Verificando arquivos j√° processados..."
        
        if os.path.exists(LOG_PROCESSADOS_FILE):
            with open(LOG_PROCESSADOS_FILE, 'r', encoding='utf-8') as f:
                processadas = set(line.strip() for line in f if line.strip())
            progresso_atual["logs"].append(f"üìù {len(processadas)} imagens j√° foram processadas anteriormente")
        else:
            processadas = set()
            progresso_atual["logs"].append("üìù Nenhuma imagem processada anteriormente")
        
        novas_imagens = [img for img in imagens if img not in processadas]
        progresso_atual["logs"].append(f"üÜï {len(novas_imagens)} novas imagens para processar")
        
        if not novas_imagens:
            progresso_atual["progresso"] = 100
            progresso_atual["status"] = "‚úÖ Todas as imagens j√° foram processadas!"
            progresso_atual["logs"].append("‚úÖ Todas as imagens j√° foram processadas!")
            return
        
        # Executar processamento principal
        progresso_atual["progresso"] = 30
        progresso_atual["status"] = "ü§ñ Iniciando an√°lise com IA Gemini..."
        progresso_atual["logs"].append("‚öôÔ∏è Carregando script de processamento...")
        
        sucesso = executar_processamento_principal()
        
        if sucesso:
            progresso_atual["progresso"] = 100
            progresso_atual["status"] = "‚úÖ Processamento conclu√≠do com sucesso!"
            progresso_atual["logs"].append("‚úÖ An√°lise conclu√≠da com sucesso!")
            
            # Verificar resultados
            if os.path.exists(ARQUIVO_SAIDA_EXCEL):
                progresso_atual["logs"].append(f"üìÑ Relat√≥rio Excel gerado: {ARQUIVO_SAIDA_EXCEL}")
                
                # Contar resultados
                try:
                    sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
                    for sheet_name, df in sheets.items():
                        if not df.empty:
                            progresso_atual["logs"].append(f"üìä {sheet_name}: {len(df)} registros")
                except Exception as e:
                    progresso_atual["logs"].append(f"‚ö†Ô∏è Erro ao ler estat√≠sticas do relat√≥rio: {e}")
            else:
                progresso_atual["logs"].append("‚ö†Ô∏è Relat√≥rio n√£o foi gerado")
        else:
            progresso_atual["status"] = "‚ùå Erro durante processamento"
            progresso_atual["logs"].append("‚ùå Erro durante o processamento principal")
        
    except Exception as e:
        erro_msg = f"Erro durante processamento: {str(e)}"
        progresso_atual["status"] = f"‚ùå Erro: {str(e)}"
        progresso_atual["logs"].append(f"‚ùå {erro_msg}")
        print(f"Erro em processar_em_background: {e}")
        
    finally:
        processamento_ativo = False
        timestamp = datetime.now().strftime('%H:%M:%S')
        progresso_atual["logs"].append(f"üèÅ Processamento finalizado √†s {timestamp}")

@app.route('/')
def index():
    """P√°gina principal com cache de resposta."""
    response = make_response()
    
    # Cache para melhor performance
    if request.headers.get('Cache-Control') != 'no-cache':
        response.headers['Cache-Control'] = 'public, max-age=60'  # 1 minuto
    
    stats = obter_estatisticas()
    resultados = obter_resultados_recentes()
    
    # Renderizar template
    html = render_template('index.html', stats=stats, resultados=resultados)
    response.set_data(html)
    response.headers['Content-Type'] = 'text/html; charset=utf-8'
    
    return response

@app.route('/upload')
def upload_page():
    """P√°gina de upload."""
    return render_template('upload.html')

@app.route('/upload_files', methods=['POST'])
def upload_files():
    """Endpoint para upload de arquivos."""
    try:
        if 'files' not in request.files:
            return jsonify({'success': False, 'message': 'Nenhum arquivo selecionado'})
        
        files = request.files.getlist('files')
        if not files or files[0].filename == '':
            return jsonify({'success': False, 'message': 'Nenhum arquivo selecionado'})
        
        # No ambiente Vercel, uploads v√£o para /tmp
        upload_dir = UPLOAD_FOLDER
        os.makedirs(upload_dir, exist_ok=True)
        
        uploaded_files = []
        for file in files:
            if file and allowed_file(file.filename):
                filename = secure_filename(file.filename)
                filepath = os.path.join(upload_dir, filename)
                file.save(filepath)
                uploaded_files.append(filename)
        
        return jsonify({
            'success': True, 
            'message': f'{len(uploaded_files)} arquivo(s) enviado(s) com sucesso!',
            'files': uploaded_files
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'Erro no upload: {str(e)}'})

@app.route('/processar', methods=['POST'])
def iniciar_processamento():
    """Inicia o processamento das imagens."""
    global processamento_ativo
    
    # Verificar se estamos na Vercel
    if 'VERCEL' in os.environ:
        return jsonify({
            'success': False, 
            'message': 'Processamento n√£o dispon√≠vel no ambiente Vercel. Use o ambiente local.'
        })
    
    if processamento_ativo:
        return jsonify({'success': False, 'message': 'Processamento j√° em andamento'})
    
    # Verificar se h√° imagens para processar
    if not os.path.exists(DIRETORIO_IMAGENS):
        return jsonify({'success': False, 'message': 'Pasta de imagens n√£o encontrada'})
    
    imagens = [f for f in os.listdir(DIRETORIO_IMAGENS) if f.lower().endswith(EXTENSOES_IMAGEM)]
    if not imagens:
        return jsonify({'success': False, 'message': 'Nenhuma imagem encontrada para processar'})
    
    # Iniciar processamento em background
    thread = threading.Thread(target=processar_em_background)
    thread.start()
    
    return jsonify({'success': True, 'message': 'Processamento iniciado!'})

@app.route('/status')
def obter_status():
    """Obt√©m o status atual do processamento."""
    # Adicionar informa√ß√µes extras ao progresso
    status_completo = progresso_atual.copy()
    
    # Adicionar contagem de imagens
    if os.path.exists(DIRETORIO_IMAGENS):
        imagens = [f for f in os.listdir(DIRETORIO_IMAGENS) if f.lower().endswith(EXTENSOES_IMAGEM)]
        status_completo['total_imagens'] = len(imagens)
    else:
        status_completo['total_imagens'] = 0
    
    return jsonify(status_completo)

@app.route('/logs')
@app.route('/visualizar_logs')
def visualizar_logs():
    """P√°gina de visualiza√ß√£o de logs em tempo real."""
    return render_template('logs.html')

@app.route('/api/logs')
def api_logs():
    """API para obter logs em tempo real."""
    try:
        logs = []
        
        # Ler log de processamento
        if os.path.exists(LOG_PROCESSADOS_FILE):
            with open(LOG_PROCESSADOS_FILE, 'r', encoding='utf-8') as f:
                linhas = f.readlines()
                logs.extend([{
                    'tipo': 'processado',
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'mensagem': linha.strip()
                } for linha in linhas[-20:] if linha.strip()])  # √öltimas 20 linhas
        
        # Ler log de consumo
        if os.path.exists(LOG_CONSUMO_FILE):
            with open(LOG_CONSUMO_FILE, 'r', encoding='utf-8') as f:
                linhas = f.readlines()
                for linha in linhas[-10:]:  # √öltimas 10 linhas
                    if linha.strip():
                        logs.append({
                            'tipo': 'consumo',
                            'timestamp': linha[:19] if len(linha) > 19 else datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            'mensagem': linha.strip()
                        })
        
        # Adicionar logs do progresso atual
        for log_msg in progresso_atual.get('logs', []):
            logs.append({
                'tipo': 'progresso',
                'timestamp': datetime.now().strftime('%H:%M:%S'),
                'mensagem': log_msg
            })
        
        return jsonify({
            'logs': logs[-50:],  # √öltimos 50 logs
            'processamento_ativo': processamento_ativo,
            'progresso': progresso_atual
        })
        
    except Exception as e:
        return jsonify({
            'logs': [{'tipo': 'erro', 'timestamp': datetime.now().strftime('%H:%M:%S'), 'mensagem': f'Erro ao ler logs: {str(e)}'}],
            'processamento_ativo': processamento_ativo,
            'progresso': progresso_atual
        })

@app.route('/relatorio')
@app.route('/visualizar_relatorio')
def visualizar_relatorio():
    """P√°gina de visualiza√ß√£o do relat√≥rio."""
    try:
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            flash('Nenhum relat√≥rio encontrado. Execute o processamento primeiro.', 'warning')
            return redirect(url_for('index'))
        
        # Verificar se o arquivo n√£o est√° vazio
        if os.path.getsize(ARQUIVO_SAIDA_EXCEL) == 0:
            flash('Arquivo de relat√≥rio est√° vazio. Execute o processamento novamente.', 'warning')
            return redirect(url_for('index'))
        
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        dados = {}
        
        if not sheets:
            flash('Relat√≥rio n√£o cont√©m dados v√°lidos.', 'warning')
            return redirect(url_for('index'))
        
        for sheet_name, df in sheets.items():
            if df is not None and not df.empty:
                # Tratar valores NaN
                df = df.fillna('-')
                dados[sheet_name] = {
                    'colunas': df.columns.tolist(),
                    'dados': df.to_dict('records'),
                    'total': len(df)
                }
        
        if not dados:
            flash('Nenhum dado v√°lido encontrado no relat√≥rio.', 'warning')
            return redirect(url_for('index'))
        
        return render_template('relatorio.html', dados=dados)
        
    except FileNotFoundError:
        flash('Arquivo de relat√≥rio n√£o encontrado.', 'danger')
        return redirect(url_for('index'))
    except PermissionError:
        flash('Sem permiss√£o para acessar o arquivo de relat√≥rio.', 'danger')
        return redirect(url_for('index'))
    except pd.errors.EmptyDataError:
        flash('Arquivo de relat√≥rio est√° vazio ou corrompido.', 'danger')
        return redirect(url_for('index'))
    except Exception as e:
        print(f"Erro detalhado ao carregar relat√≥rio: {e}")
        flash(f'Erro ao carregar relat√≥rio: {str(e)}', 'danger')
        return redirect(url_for('index'))

@app.route('/download_relatorio')
def download_relatorio():
    """Download do relat√≥rio em Excel."""
    try:
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            flash('Relat√≥rio n√£o encontrado', 'warning')
            return redirect(url_for('index'))
        
        return send_file(
            ARQUIVO_SAIDA_EXCEL,
            as_attachment=True,
            download_name=f'Relatorio_Avarias_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx'
        )
    except Exception as e:
        flash(f'Erro no download: {str(e)}', 'danger')
        return redirect(url_for('index'))

@app.route('/configuracoes')
def configuracoes():
    """P√°gina de configura√ß√µes."""
    config = carregar_configuracao()
    stats = obter_estatisticas()
    
    # Avisar sobre limita√ß√µes na Vercel
    if 'VERCEL' in os.environ:
        config['_vercel_env'] = True
    
    return render_template('configuracoes.html', config=config, stats=stats)

@app.route('/salvar_configuracao', methods=['POST'])
def salvar_configuracao_route():
    """Salva as configura√ß√µes do usu√°rio."""
    try:
        data = request.json
        config = carregar_configuracao()
        
        # Atualizar configura√ß√µes
        if 'api' in data:
            config['api'].update(data['api'])
        if 'processamento' in data:
            config['processamento'].update(data['processamento'])
        if 'interface' in data:
            config['interface'].update(data['interface'])
        
        # No ambiente Vercel, apenas simular salvamento
        if 'VERCEL' in os.environ:
            return jsonify({
                'success': True, 
                'message': 'No ambiente Vercel, use vari√°veis de ambiente para configura√ß√µes'
            })
        
        if salvar_configuracao(config):
            return jsonify({'success': True, 'message': 'Configura√ß√µes salvas com sucesso!'})
        else:
            return jsonify({'success': False, 'message': 'Erro ao salvar configura√ß√µes'})
    
    except Exception as e:
        return jsonify({'success': False, 'message': f'Erro: {str(e)}'})

@app.route('/editar_dados')
def editar_dados():
    """P√°gina de edi√ß√£o de dados do relat√≥rio."""
    try:
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            flash('Nenhum relat√≥rio encontrado para editar.', 'warning')
            return redirect(url_for('configuracoes'))
        
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        dados = {}
        
        for sheet_name, df in sheets.items():
            if df is not None and not df.empty:
                # Adicionar √≠ndice para edi√ß√£o
                df = df.reset_index()
                df['id_linha'] = df.index
                
                # Tratar valores NaN para evitar erros no template
                df = df.fillna('')  # Substitui NaN por string vazia
                
                dados[sheet_name] = {
                    'colunas': df.columns.tolist(),
                    'dados': df.to_dict('records'),
                    'total': len(df)
                }
        
        return render_template('editar_dados.html', dados=dados)
        
    except Exception as e:
        flash(f'Erro ao carregar dados para edi√ß√£o: {str(e)}', 'danger')
        return redirect(url_for('configuracoes'))

@app.route('/salvar_edicao', methods=['POST'])
def salvar_edicao():
    """Salva as edi√ß√µes feitas nos dados."""
    try:
        data = request.json
        sheet_name = data.get('sheet_name')
        linha_id = data.get('linha_id')
        campo = data.get('campo')
        novo_valor = data.get('novo_valor')
        
        print(f"üìù Salvando edi√ß√£o: Sheet={sheet_name}, Linha={linha_id}, Campo={campo}, Valor={novo_valor}")
        
        # Valida√ß√£o mais detalhada
        if not sheet_name:
            return jsonify({'success': False, 'message': 'Nome da planilha √© obrigat√≥rio'})
        if linha_id is None:
            return jsonify({'success': False, 'message': 'ID da linha √© obrigat√≥rio'})
        if not campo:
            return jsonify({'success': False, 'message': 'Nome do campo √© obrigat√≥rio'})
        if novo_valor is None:
            novo_valor = ''  # Permitir valores vazios
        
        # Verificar se arquivo existe
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
        
        # Ler arquivo Excel
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        
        if sheet_name not in sheets:
            return jsonify({'success': False, 'message': f'Planilha "{sheet_name}" n√£o encontrada'})
        
        df = sheets[sheet_name]
        
        # Verificar se a linha existe
        if linha_id >= len(df) or linha_id < 0:
            return jsonify({'success': False, 'message': f'Linha {linha_id} n√£o encontrada (total: {len(df)} linhas)'})
        
        # Verificar se a coluna existe
        if campo not in df.columns:
            return jsonify({'success': False, 'message': f'Campo "{campo}" n√£o encontrado. Campos dispon√≠veis: {list(df.columns)}'})
        
        # Validar tipos de dados se necess√°rio
        original_value = df.at[linha_id, campo]
        print(f"üìä Valor original: {original_value} -> Novo valor: {novo_valor}")
        
        # Atualizar valor
        df.at[linha_id, campo] = novo_valor
        sheets[sheet_name] = df
        
        # Criar backup antes de salvar
        backup_file = f"{ARQUIVO_SAIDA_EXCEL}.bak"
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_file)
        
        # Salvar arquivo Excel
        with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:
            for nome_sheet, dataframe in sheets.items():
                dataframe.to_excel(writer, sheet_name=nome_sheet, index=False)
        
        print(f"‚úÖ Edi√ß√£o salva com sucesso!")
        return jsonify({'success': True, 'message': f'Campo "{campo}" atualizado com sucesso!'})
        
    except FileNotFoundError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
    except PermissionError:
        return jsonify({'success': False, 'message': 'Sem permiss√£o para editar o arquivo. Verifique se est√° aberto em outro programa'})
    except pd.errors.EmptyDataError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio est√° vazio ou corrompido'})
    except Exception as e:
        print(f"‚ùå Erro ao salvar edi√ß√£o: {e}")
        return jsonify({'success': False, 'message': f'Erro inesperado: {str(e)}'})

@app.route('/salvar_edicao_completa', methods=['POST'])
def salvar_edicao_completa():
    """Salva as edi√ß√µes completas feitas em uma linha."""
    try:
        data = request.json
        sheet_name = data.get('sheet_name')
        linha_id = data.get('linha_id')
        dados_linha = data.get('dados_linha')
        
        print(f"üìù Salvando edi√ß√£o completa: Sheet={sheet_name}, Linha={linha_id}, Dados={dados_linha}")
        
        # Valida√ß√£o
        if not sheet_name:
            return jsonify({'success': False, 'message': 'Nome da planilha √© obrigat√≥rio'})
        if linha_id is None:
            return jsonify({'success': False, 'message': 'ID da linha √© obrigat√≥rio'})
        if not dados_linha or not isinstance(dados_linha, dict):
            return jsonify({'success': False, 'message': 'Dados da linha s√£o obrigat√≥rios'})
        
        # Verificar se arquivo existe
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
        
        # Ler arquivo Excel
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        
        if sheet_name not in sheets:
            return jsonify({'success': False, 'message': f'Planilha "{sheet_name}" n√£o encontrada'})
        
        df = sheets[sheet_name]
        
        # Verificar se a linha existe
        if linha_id >= len(df) or linha_id < 0:
            return jsonify({'success': False, 'message': f'Linha {linha_id} n√£o encontrada (total: {len(df)} linhas)'})
        
        # Criar backup antes de salvar
        backup_file = f"{ARQUIVO_SAIDA_EXCEL}.bak"
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_file)
        
        # Atualizar todos os campos fornecidos
        campos_atualizados = []
        for campo, novo_valor in dados_linha.items():
            if campo in df.columns:
                valor_original = df.at[linha_id, campo]
                df.at[linha_id, campo] = novo_valor
                campos_atualizados.append(campo)
                print(f"üìä {campo}: {valor_original} -> {novo_valor}")
            else:
                print(f"‚ö†Ô∏è Campo '{campo}' n√£o encontrado na planilha")
        
        if not campos_atualizados:
            return jsonify({'success': False, 'message': 'Nenhum campo v√°lido foi encontrado para atualizar'})
        
        sheets[sheet_name] = df
        
        # Salvar arquivo Excel
        with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:
            for nome_sheet, dataframe in sheets.items():
                dataframe.to_excel(writer, sheet_name=nome_sheet, index=False)
        
        print(f"‚úÖ Edi√ß√£o completa salva com sucesso! Campos atualizados: {', '.join(campos_atualizados)}")
        return jsonify({'success': True, 'message': f'Linha atualizada com sucesso! ({len(campos_atualizados)} campos alterados)'})
        
    except FileNotFoundError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
    except PermissionError:
        return jsonify({'success': False, 'message': 'Sem permiss√£o para editar o arquivo. Verifique se est√° aberto em outro programa'})
    except pd.errors.EmptyDataError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio est√° vazio ou corrompido'})
    except Exception as e:
        print(f"‚ùå Erro ao salvar edi√ß√£o completa: {e}")
        return jsonify({'success': False, 'message': f'Erro inesperado: {str(e)}'})

@app.route('/excluir_linha', methods=['POST'])
def excluir_linha():
    """Exclui uma linha do relat√≥rio."""
    try:
        data = request.json
        sheet_name = data.get('sheet_name')
        linha_id = data.get('linha_id')
        
        print(f"üóëÔ∏è Excluindo linha: Sheet={sheet_name}, Linha={linha_id}")
        
        if not sheet_name:
            return jsonify({'success': False, 'message': 'Nome da planilha √© obrigat√≥rio'})
        if linha_id is None:
            return jsonify({'success': False, 'message': 'ID da linha √© obrigat√≥rio'})
        
        # Verificar se arquivo existe
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
        
        # Ler arquivo Excel
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        
        if sheet_name not in sheets:
            return jsonify({'success': False, 'message': f'Planilha "{sheet_name}" n√£o encontrada'})
        
        df = sheets[sheet_name]
        
        # Verificar se a linha existe
        if linha_id >= len(df) or linha_id < 0:
            return jsonify({'success': False, 'message': f'Linha {linha_id} n√£o encontrada (total: {len(df)} linhas)'})
        
        # Criar backup antes de excluir
        backup_file = f"{ARQUIVO_SAIDA_EXCEL}.bak"
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_file)
        
        # Remover linha
        df = df.drop(df.index[linha_id]).reset_index(drop=True)
        sheets[sheet_name] = df
        
        # Salvar arquivo Excel
        with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:
            for nome_sheet, dataframe in sheets.items():
                dataframe.to_excel(writer, sheet_name=nome_sheet, index=False)
        
        print(f"‚úÖ Linha exclu√≠da com sucesso!")
        return jsonify({'success': True, 'message': 'Linha exclu√≠da com sucesso!'})
        
    except FileNotFoundError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
    except PermissionError:
        return jsonify({'success': False, 'message': 'Sem permiss√£o para editar o arquivo. Verifique se est√° aberto em outro programa'})
    except Exception as e:
        print(f"‚ùå Erro ao excluir linha: {e}")
        return jsonify({'success': False, 'message': f'Erro inesperado: {str(e)}'})

@app.route('/mover_item', methods=['POST'])
def mover_item():
    """Move um item de uma tabela para outra."""
    try:
        data = request.json
        sheet_origem = data.get('sheet_origem')
        sheet_destino = data.get('sheet_destino')
        linha_id = data.get('linha_id')
        
        print(f"üîÑ Movendo item: {sheet_origem} -> {sheet_destino}, Linha={linha_id}")
        
        # Valida√ß√£o
        if not sheet_origem or not sheet_destino:
            return jsonify({'success': False, 'message': 'Planilhas de origem e destino s√£o obrigat√≥rias'})
        if linha_id is None:
            return jsonify({'success': False, 'message': 'ID da linha √© obrigat√≥rio'})
        if sheet_origem == sheet_destino:
            return jsonify({'success': False, 'message': 'Planilha de origem e destino n√£o podem ser iguais'})
        
        # Verificar se arquivo existe
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
        
        # Ler arquivo Excel
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        
        if sheet_origem not in sheets:
            return jsonify({'success': False, 'message': f'Planilha de origem "{sheet_origem}" n√£o encontrada'})
        if sheet_destino not in sheets:
            # Se a planilha de destino n√£o existir, criar uma vazia
            # Definir colunas baseadas no tipo de planilha
            if sheet_destino == 'Avarias':
                colunas_destino = ["Produto", "Detalhes", "Observa√ß√£o da Mensagem", "Caminho da Imagem", "Ver Imagem"]
            elif sheet_destino == 'Uso Interno':
                colunas_destino = ["Produto", "Detalhes", "Observa√ß√£o da Mensagem", "Caminho da Imagem", "Ver Imagem"]
            elif sheet_destino == 'Erros de An√°lise':
                colunas_destino = ["Arquivo", "Detalhes do Erro", "Observa√ß√£o da Mensagem", "Caminho da Imagem", "Ver Imagem"]
            else:
                return jsonify({'success': False, 'message': f'Tipo de planilha destino "{sheet_destino}" n√£o reconhecido'})
            
            sheets[sheet_destino] = pd.DataFrame(columns=colunas_destino)
        
        df_origem = sheets[sheet_origem]
        df_destino = sheets[sheet_destino]
        
        # Verificar se a linha existe na origem
        if linha_id >= len(df_origem) or linha_id < 0:
            return jsonify({'success': False, 'message': f'Linha {linha_id} n√£o encontrada na planilha origem (total: {len(df_origem)} linhas)'})
        
        # Obter dados da linha
        linha_dados = df_origem.iloc[linha_id].copy()
        
        # Criar backup antes de mover
        backup_file = f"{ARQUIVO_SAIDA_EXCEL}.bak"
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_file)
        
        # Adaptar dados para a planilha de destino
        nova_linha = {}
        
        if sheet_destino == 'Avarias':
            nova_linha = {
                "Produto": linha_dados.get("Produto", linha_dados.get("Arquivo", "N/A")),
                "Detalhes": linha_dados.get("Detalhes", linha_dados.get("Detalhes do Erro", "Movido de outra planilha")),
                "Observa√ß√£o da Mensagem": linha_dados.get("Observa√ß√£o da Mensagem", "N/A"),
                "Caminho da Imagem": linha_dados.get("Caminho da Imagem", "N/A"),
                "Ver Imagem": linha_dados.get("Ver Imagem", linha_dados.get("Caminho da Imagem", "N/A"))
            }
        elif sheet_destino == 'Uso Interno':
            nova_linha = {
                "Produto": linha_dados.get("Produto", linha_dados.get("Arquivo", "N/A")),
                "Detalhes": linha_dados.get("Detalhes", linha_dados.get("Detalhes do Erro", "Movido de outra planilha")),
                "Observa√ß√£o da Mensagem": linha_dados.get("Observa√ß√£o da Mensagem", "N/A"),
                "Caminho da Imagem": linha_dados.get("Caminho da Imagem", "N/A"),
                "Ver Imagem": linha_dados.get("Ver Imagem", linha_dados.get("Caminho da Imagem", "N/A"))
            }
        elif sheet_destino == 'Erros de An√°lise':
            nova_linha = {
                "Arquivo": linha_dados.get("Arquivo", linha_dados.get("Produto", "N/A")),
                "Detalhes do Erro": linha_dados.get("Detalhes do Erro", linha_dados.get("Detalhes", "Movido de outra planilha")),
                "Observa√ß√£o da Mensagem": linha_dados.get("Observa√ß√£o da Mensagem", "N/A"),
                "Caminho da Imagem": linha_dados.get("Caminho da Imagem", "N/A"),
                "Ver Imagem": linha_dados.get("Ver Imagem", linha_dados.get("Caminho da Imagem", "N/A"))
            }
        
        # Adicionar nova linha √† planilha de destino
        df_destino = pd.concat([df_destino, pd.DataFrame([nova_linha])], ignore_index=True)
        
        # Remover linha da planilha de origem
        df_origem = df_origem.drop(df_origem.index[linha_id]).reset_index(drop=True)
        
        # Atualizar sheets
        sheets[sheet_origem] = df_origem
        sheets[sheet_destino] = df_destino
        
        # Salvar arquivo Excel
        with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:
            for nome_sheet, dataframe in sheets.items():
                if not dataframe.empty:  # S√≥ salvar planilhas n√£o vazias
                    dataframe.to_excel(writer, sheet_name=nome_sheet, index=False)
        
        produto_nome = nova_linha.get("Produto", nova_linha.get("Arquivo", "Item"))
        print(f"‚úÖ Item '{produto_nome}' movido com sucesso de '{sheet_origem}' para '{sheet_destino}'!")
        
        return jsonify({
            'success': True, 
            'message': f"Item '{produto_nome}' movido com sucesso de '{sheet_origem}' para '{sheet_destino}'!"
        })
        
    except FileNotFoundError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
    except PermissionError:
        return jsonify({'success': False, 'message': 'Sem permiss√£o para editar o arquivo. Verifique se est√° aberto em outro programa'})
    except pd.errors.EmptyDataError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio est√° vazio ou corrompido'})
    except Exception as e:
        print(f"‚ùå Erro ao mover item: {e}")
        return jsonify({'success': False, 'message': f'Erro inesperado: {str(e)}'})

@app.route('/adicionar_linha', methods=['POST'])
def adicionar_linha():
    """Adiciona uma nova linha ao relat√≥rio."""
    try:
        data = request.json
        sheet_name = data.get('sheet_name')
        dados_linha = data.get('dados_linha')
        
        print(f"‚ûï Adicionando linha: Sheet={sheet_name}, Dados={dados_linha}")
        
        if not sheet_name:
            return jsonify({'success': False, 'message': 'Nome da planilha √© obrigat√≥rio'})
        if not dados_linha or not isinstance(dados_linha, dict):
            return jsonify({'success': False, 'message': 'Dados da linha s√£o obrigat√≥rios'})
        
        # Verificar se arquivo existe
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
        
        # Ler arquivo Excel
        sheets = pd.read_excel(ARQUIVO_SAIDA_EXCEL, sheet_name=None, engine='openpyxl')
        
        if sheet_name not in sheets:
            return jsonify({'success': False, 'message': f'Planilha "{sheet_name}" n√£o encontrada'})
        
        df = sheets[sheet_name]
        
        # Validar campos obrigat√≥rios (se aplic√°vel)
        campos_obrigatorios = ['Produto', 'Quantidade']
        for campo in campos_obrigatorios:
            if campo in df.columns and not dados_linha.get(campo, '').strip():
                return jsonify({'success': False, 'message': f'Campo "{campo}" √© obrigat√≥rio'})
        
        # Criar nova linha com as colunas existentes
        nova_linha = {}
        for coluna in df.columns:
            valor = dados_linha.get(coluna, '')
            # Adicionar timestamp para campos de data se estiverem vazios
            if 'Data' in coluna and not valor:
                valor = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            nova_linha[coluna] = valor
        
        # Criar backup antes de adicionar
        backup_file = f"{ARQUIVO_SAIDA_EXCEL}.bak"
        if os.path.exists(ARQUIVO_SAIDA_EXCEL):
            shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_file)
        
        # Adicionar nova linha
        df = pd.concat([df, pd.DataFrame([nova_linha])], ignore_index=True)
        sheets[sheet_name] = df
        
        # Salvar arquivo Excel
        with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:
            for nome_sheet, dataframe in sheets.items():
                dataframe.to_excel(writer, sheet_name=nome_sheet, index=False)
        
        print(f"‚úÖ Linha adicionada com sucesso! Total de linhas: {len(df)}")
        return jsonify({'success': True, 'message': f'Nova linha adicionada com sucesso! Total: {len(df)} registros'})
        
    except FileNotFoundError:
        return jsonify({'success': False, 'message': 'Arquivo de relat√≥rio n√£o encontrado'})
    except PermissionError:
        return jsonify({'success': False, 'message': 'Sem permiss√£o para editar o arquivo. Verifique se est√° aberto em outro programa'})
    except Exception as e:
        print(f"‚ùå Erro ao adicionar linha: {e}")
        return jsonify({'success': False, 'message': f'Erro inesperado: {str(e)}'})

@app.route('/backup_relatorio')
def backup_relatorio():
    """Cria backup do relat√≥rio atual."""
    try:
        if not os.path.exists(ARQUIVO_SAIDA_EXCEL):
            return jsonify({'success': False, 'message': 'Nenhum relat√≥rio encontrado'})
        
        # Criar nome do backup com timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_nome = f"Relatorio_Backup_{timestamp}.xlsx"
        backup_path = os.path.join("resultados", backup_nome)
        
        # Copiar arquivo
        shutil.copy2(ARQUIVO_SAIDA_EXCEL, backup_path)
        
        return jsonify({
            'success': True, 
            'message': f'Backup criado: {backup_nome}',
            'backup_file': backup_nome
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'Erro ao criar backup: {str(e)}'})

@app.route('/download_backup/<filename>')
def download_backup(filename):
    """Download de arquivo de backup."""
    try:
        backup_path = os.path.join("resultados", filename)
        if not os.path.exists(backup_path):
            flash('Backup n√£o encontrado', 'warning')
            return redirect(url_for('configuracoes'))
        
        return send_file(backup_path, as_attachment=True, download_name=filename)
    except Exception as e:
        flash(f'Erro no download: {str(e)}', 'danger')
        return redirect(url_for('configuracoes'))

@app.route('/limpar_dados', methods=['POST'])
def limpar_dados():
    """Limpa dados processados."""
    try:
        tipo = request.json.get('tipo', '')
        
        if tipo == 'logs':
            if os.path.exists(LOG_PROCESSADOS_FILE):
                os.remove(LOG_PROCESSADOS_FILE)
            if os.path.exists(LOG_CONSUMO_FILE):
                os.remove(LOG_CONSUMO_FILE)
            message = 'Logs limpos com sucesso!'
            
        elif tipo == 'relatorio':
            if os.path.exists(ARQUIVO_SAIDA_EXCEL):
                os.remove(ARQUIVO_SAIDA_EXCEL)
            message = 'Relat√≥rio removido com sucesso!'
            
        elif tipo == 'imagens':
            if os.path.exists(DIRETORIO_IMAGENS):
                for arquivo in os.listdir(DIRETORIO_IMAGENS):
                    arquivo_path = os.path.join(DIRETORIO_IMAGENS, arquivo)
                    if os.path.isfile(arquivo_path):
                        os.remove(arquivo_path)
            message = 'Imagens removidas com sucesso!'
            
        else:
            return jsonify({'success': False, 'message': 'Tipo de limpeza inv√°lido'})
        
        return jsonify({'success': True, 'message': message})
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'Erro: {str(e)}'})

@app.route('/download_config')
def download_config():
    """Download das configura√ß√µes como backup"""
    try:
        config_path = os.path.join(app.root_path, 'config.json')
        if not os.path.exists(config_path):
            flash('Arquivo de configura√ß√£o n√£o encontrado.', 'warning')
            return redirect(url_for('configuracoes'))
        
        return send_file(config_path, as_attachment=True, download_name='config_backup.json')
    except Exception as e:
        flash(f'Erro ao fazer download: {str(e)}', 'error')
        return redirect(url_for('configuracoes'))

@app.route('/api/stats')
def api_stats():
    """API para obter estat√≠sticas atualizadas."""
    return jsonify(obter_estatisticas())

@app.route('/imagem/<path:filename>')
def servir_imagem(filename):
    """Serve imagens do diret√≥rio de imagens com cache otimizado."""
    try:
        # Verificar se o arquivo existe e √© uma imagem
        caminho_completo = os.path.join(DIRETORIO_IMAGENS, filename)
        
        if not os.path.exists(caminho_completo):
            return jsonify({'error': 'Imagem n√£o encontrada'}), 404
        
        # Verificar se √© realmente uma imagem
        _, ext = os.path.splitext(filename.lower())
        if ext not in EXTENSOES_IMAGEM:
            return jsonify({'error': 'Arquivo n√£o √© uma imagem v√°lida'}), 400
        
        # Configurar headers de cache para imagens
        def add_cache_headers(response):
            # Cache por 1 hora para imagens est√°ticas
            response.headers['Cache-Control'] = 'public, max-age=3600'
            response.headers['ETag'] = f'"{hash(filename + str(os.path.getmtime(caminho_completo)))}"'
            return response
        
        # Verificar ETag para cache condicional
        if_none_match = request.headers.get('If-None-Match')
        current_etag = f'"{hash(filename + str(os.path.getmtime(caminho_completo)))}"'
        
        if if_none_match == current_etag:
            response = make_response('', 304)  # Not Modified
            response.headers['ETag'] = current_etag
            return response
        
        response = make_response(send_file(caminho_completo))
        return add_cache_headers(response)
        
    except Exception as e:
        print(f"‚ùå Erro ao servir imagem {filename}: {e}")
        return jsonify({'error': 'Erro interno do servidor'}), 500

# Fun√ß√£o de entrada para Vercel (WSGI handler)
def application(environ, start_response):
    """Handler WSGI para Vercel."""
    return app(environ, start_response)

# Fun√ß√£o adicional para compatibilidade
def handler(request):
    """Handler alternativo para Vercel."""
    return app

# Para desenvolvimento local
if __name__ == '__main__':
    # Garantir que as pastas necess√°rias existam apenas em desenvolvimento
    if 'VERCEL' not in os.environ:
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        os.makedirs(os.path.join(BASE_PATH, 'resultados'), exist_ok=True)
    
    print("üöÄ Iniciando Interface Web do Analisador de Avarias")
    print("üì± Acesse: http://localhost:5000")
    print("üåç Compat√≠vel com Vercel para deploy")
    print("=" * 50)
    
    app.run(debug=True, host='0.0.0.0', port=5000)

# Exportar app para Vercel
app_vercel = app
